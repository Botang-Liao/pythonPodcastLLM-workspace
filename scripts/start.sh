#!/bin/bash

echo "ðŸ” æª¢æŸ¥ GPU èˆ‡ CUDA ç‰ˆæœ¬..."

# é è¨­å€¼
TORCH_VERSION=2.4.1
TORCHVISION_VERSION=0.19.1
TORCHAUDIO_VERSION=2.4.1

# åˆ¤æ–·æ˜¯å¦æœ‰ GPU
if command -v nvidia-smi &> /dev/null; then
    CUDA_VERSION=$(nvidia-smi | grep -oP 'CUDA Version: \K[0-9.]+')

    echo "âœ… åµæ¸¬åˆ° NVIDIA GPUï¼ŒCUDA ç‰ˆæœ¬ç‚º $CUDA_VERSION"

    # åˆ¤æ–·é©ç”¨çš„ PyTorch CUDA wheel
    case "$CUDA_VERSION" in
        12.4*) TORCH_CUDA=cu124 ;;
        12.1*) TORCH_CUDA=cu121 ;;
        11.8*) TORCH_CUDA=cu118 ;;
        *) TORCH_CUDA=cpu ;; # æœªçŸ¥ç‰ˆæœ¬å‰‡å›žé€€åˆ° CPU
    esac
else
    echo "âŒ æ²’æœ‰åµæ¸¬åˆ° GPUï¼Œå°‡å®‰è£ CPU ç‰ˆæœ¬"
    TORCH_CUDA=cpu
fi

echo "â¬‡ï¸ å®‰è£ torch==${TORCH_VERSION} with ${TORCH_CUDA} backend..."
pip3 install torch==${TORCH_VERSION} \
              torchvision==${TORCHVISION_VERSION} \
              torchaudio==${TORCHAUDIO_VERSION} \
              --index-url https://download.pytorch.org/whl/${TORCH_CUDA}

pip3 install "sentence-transformers>=2.6.1,<3.0.0"

sudo chown "$(id -u)":"$(id -g)" /home/"$(id -un)"/.vscode-server && chmod 755 /home/"$(id -un)"/.vscode-server
sudo chown "$(id -u)":"$(id -g)" /home/"$(id -un)"/projects && chmod 755 /home/"$(id -un)"/projects

# keep the container running
tail -f /dev/null
